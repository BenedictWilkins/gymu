{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68f7028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0]]\n"
     ]
    }
   ],
   "source": [
    "a = \n",
    "a[0].append(0)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f3492",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "import numpy as np\n",
    "import webdataset as wb\n",
    "import os\n",
    "\n",
    "class ParallelWebDataset(IterableDataset, wb.Composable, wb.Shorthands):\n",
    "    \n",
    "    def __init__(self, paths, num_workers):\n",
    "        self.num_workers = num_workers\n",
    "        self.paths = [x.tolist() for x in np.array_split(paths, num_workers)]\n",
    "        self.worker_id = None \n",
    "        self.dataset = None\n",
    "        \n",
    "        self._processchain = []\n",
    "        \n",
    "    def initialise(self, worker_id):\n",
    "        self.worker_id = worker_id\n",
    "       \n",
    "    def __iter__(self):\n",
    "        print(self.paths[self.worker_id])\n",
    "        self.dataset = wb.WebDataset(self.paths[self.worker_id])\n",
    "        self.dataset_iter = iter(self.dataset.map(lambda x: (os.getpid(), x['__key__'], x['__worker__'], x['__url__'])))\n",
    "        #print(os.getpid(), self.worker_id, self.paths[self.worker_id])\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        #print(f\"NEXT {os.getpid()}\")\n",
    "        return next(self.dataset_iter)\n",
    "    \n",
    "class ParralellWebDataLoader(DataLoader):\n",
    "    \n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        assert isinstance(dataset, ParallelWebDataset)\n",
    "        kwargs['worker_init_fn'] = dataset.initialise\n",
    "        kwargs['num_workers'] = dataset.num_workers\n",
    "        super().__init__(dataset, **kwargs)\n",
    "        \n",
    "import glob\n",
    "import numpy as np\n",
    "import gymu\n",
    "import gym_pygame\n",
    "\n",
    "env = gymu.make(\"Alone-v0\")\n",
    "iterator = gymu.iterator(env, mode=gymu.mode.sard, max_length=10)\n",
    "for i in range(2):\n",
    "    gymu.data.write_episode(iterator, path=f\"Alone-v0/ep-{i}\")\n",
    "\n",
    "episodes = glob.glob(\"./Alone-v0/*.tar.gz\")\n",
    "dataset = ParallelWebDataset(episodes, num_workers=2)\n",
    "loader = ParralellWebDataLoader(dataset)\n",
    "\n",
    "for x in loader:\n",
    "    print(x)\n",
    "\n",
    "\n",
    "\n",
    "#for x in loader:\n",
    " #   print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7721f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import gymu\n",
    "from gymu.data import Composable\n",
    "import gym_pygame\n",
    "import jnu as J\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import webdataset as wb\n",
    "\n",
    "env = gymu.make(\"Alone-v0\")\n",
    "iterator = gymu.iterator(env, mode=gymu.mode.sard, max_length=20)\n",
    "#for i in range(5):\n",
    "#    gymu.data.write_episode(iterator, path=f\"Alone-v0/ep-{i}\")\n",
    "\n",
    "episodes = glob.glob(\"./Alone-v0/*.tar.gz\")\n",
    "#dataset = wb.WebDataset(episodes, shardshuffle=True)\n",
    "#dataset = dataset.map(lambda x: (x['__key__'], x['__worker__'], x['__url__'].split(\"/\")[-1].split(\".\")[0]))\n",
    "\n",
    "dataset = gymu.data.dataset(episodes)\n",
    "print(type(dataset).__mro__)\n",
    "dataset = dataset.gymu.decode(keep_meta=False)\n",
    "print(type(dataset))\n",
    "\n",
    "dataset = dataset.gymu.mode(gymu.mode.sa)\n",
    "dataset = dataset.gymu.to_tensor_dataset(show_progress=True)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "for s,a in loader:\n",
    "    print(s.shape, a.shape)\n",
    "    #print(x['__key__'], x['__worker__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1d41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f212bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import gymu\n",
    "from gymu.data import Composable\n",
    "import gym_pygame\n",
    "import jnu as J\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "env = gymu.make(\"Alone-v0\")\n",
    "iterator = gymu.iterator(env, mode=gymu.mode.sard, max_length=20)\n",
    "for i in range(5):\n",
    "    gymu.data.write_episode(iterator, path=f\"Alone-v0/ep-{i}\")\n",
    "\n",
    "episodes = glob.glob(\"./Alone-v0/*.tar.gz\")\n",
    "\n",
    "dataset = gymu.data.dataset(episodes, shardshuffle=False).then(Composable.decode(keep_meta=True))\n",
    "#dataset = dataset.shuffle(1000, initial=200)#.map(lambda x: (x['__key__'],))\n",
    "\n",
    "loader = DataLoader(dataset, num_workers=2)\n",
    "\n",
    "for x in loader:\n",
    "    print(x['__key__'], x['__worker__'], x['__url__'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymu.utils import overload\n",
    "\n",
    "@overload\n",
    "def f():\n",
    "    pass\n",
    "\n",
    "@f.args(int, int)\n",
    "def f(x, y):\n",
    "    print('two integers')\n",
    "\n",
    "@f.args(float)\n",
    "def f(x):\n",
    "    print('one float')\n",
    "\n",
    "    \n",
    "print(f.cases)\n",
    "f(1.)\n",
    "f(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import pairwise\n",
    "\n",
    "\n",
    "iterator = pairwise([1,2,3,4,5])\n",
    "\n",
    "x = next(iterator)\n",
    "for x in iterator:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymu\n",
    "import jnu as J\n",
    "import numpy as np\n",
    "\n",
    "dataset = gymu.data.dataset([\"./NORMAL-300k/ep-0000.tar.gz\",\"./NORMAL-300k/ep-0000.tar.gz\"]).then(gymu.data.Composable.decode())\n",
    "dataset = dataset.then(gymu.data.Composable.mode(gymu.mode.sas))\n",
    "\n",
    "s = [np.concatenate([x.state, (x.next_state if x.next_state is not None else np.zeros_like(x.state))], axis=-1) for x in dataset]\n",
    " \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.images(s, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c182e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import gymu\n",
    "from gymu.data import Composable\n",
    "import gym_pygame\n",
    "import jnu as J\n",
    "\n",
    "\n",
    "env = gymu.make(\"Alone-v0\")\n",
    "iterator = gymu.iterator(env, mode=gymu.mode.sard, max_length=20)\n",
    "gymu.data.write_episode(iterator, path=\"Alone-v0/ep-0.tar.gz\")\n",
    "gymu.data.write_episode(iterator, path=\"Alone-v0/ep-1.tar.gz\")\n",
    "\n",
    "episodes = glob.glob(\"./Alone-v0/*.tar.gz\")\n",
    "dataset = gymu.data.dataset(episodes).then(Composable.decode())\n",
    "dataset = dataset.then(gymu.data.Composable.mode(gymu.mode.sas, ignore_last=False))\n",
    "\n",
    "s = [np.concatenate([x.state, (x.next_state if x.next_state is not None else np.zeros_like(x.state))], axis=-1) for x in dataset]\n",
    "J.images(s)      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fca24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jnu as J\n",
    "import itertools\n",
    "import gymu\n",
    "import glob\n",
    "from gymu.data import Composable\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "episodes = glob.glob(\"./NORMAL-300k/*.tar.gz\")\n",
    "\n",
    "dataset = gymu.data.dataset(episodes)\n",
    "dataset = dataset.then(Composable.mode(gymu.mode.sa))\n",
    "dataset = dataset.shuffle(256).batched(256)\n",
    "loader = DataLoader(dataset, batch_size=None, num_workers=12, prefetch_factor=16)\n",
    "\n",
    "for (s, a) in loader:\n",
    "    print(s.shape, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748134d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
