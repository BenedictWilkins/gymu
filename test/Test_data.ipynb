{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97df46a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4193490afa43d68a9f6b46d0df2f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8188e88803a244888c179d79e29663e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83e07473c5e40f9af40404ca8d36ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', layout=Layout(width='99%'), max=35), Output()), _dom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d246b409144d90b68b86d9bb8079be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=32, width=96),), layout=Layout(align_items='center', display='flex', flex_flow='r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<jnu.image._image.Image at 0x7facc09cbdf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import gymu\n",
    "from gymu.data import Composable\n",
    "import gym_pygame\n",
    "import jnu as J\n",
    "\n",
    "\n",
    "env = gymu.make(\"Alone-v0\")\n",
    "iterator = gymu.iterator(env, mode=gymu.mode.sard, max_length=20)\n",
    "gymu.data.write_episode(iterator, path=\"Alone-v0/ep-0.tar.gz\")\n",
    "gymu.data.write_episode(iterator, path=\"Alone-v0/ep-1.tar.gz\")\n",
    "\n",
    "episodes = glob.glob(\"./Alone-v0/*.tar.gz\")\n",
    "dataset = gymu.data.dataset(episodes).then(Composable.decode())\n",
    "dataset = dataset.then(gymu.data.Composable.window(window_size=3))\n",
    "\n",
    "def cat(x):\n",
    "    x['state'] = np.concatenate([*x['state']], axis=-1)\n",
    "    return x\n",
    "dataset = dataset.map(cat)\n",
    "dataset = dataset.then(gymu.data.Composable.mode(gymu.mode.sa))\n",
    "\n",
    "J.images([x.state for x in dataset])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymu.utils import overload\n",
    "\n",
    "@overload\n",
    "def f():\n",
    "    pass\n",
    "\n",
    "@f.args(int, int)\n",
    "def f(x, y):\n",
    "    print('two integers')\n",
    "\n",
    "@f.args(float)\n",
    "def f(x):\n",
    "    print('one float')\n",
    "\n",
    "    \n",
    "print(f.cases)\n",
    "f(1.)\n",
    "f(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import pairwise\n",
    "\n",
    "\n",
    "iterator = pairwise([1,2,3,4,5])\n",
    "\n",
    "x = next(iterator)\n",
    "for x in iterator:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59897f80",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './NORMAL-300k/ep-0000.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m gymu\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdataset([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./NORMAL-300k/ep-0000.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./NORMAL-300k/ep-0000.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mthen(gymu\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mComposable\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mthen(gymu\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mComposable\u001b[38;5;241m.\u001b[39mmode(gymu\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39msas))\n\u001b[0;32m----> 8\u001b[0m s \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mconcatenate([x\u001b[38;5;241m.\u001b[39mstate, (x\u001b[38;5;241m.\u001b[39mnext_state \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mnext_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros_like(x\u001b[38;5;241m.\u001b[39mstate))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     11\u001b[0m J\u001b[38;5;241m.\u001b[39mimages([[x\u001b[38;5;241m.\u001b[39mstate] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset])\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m gymu\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdataset([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./NORMAL-300k/ep-0000.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./NORMAL-300k/ep-0000.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mthen(gymu\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mComposable\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mthen(gymu\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mComposable\u001b[38;5;241m.\u001b[39mmode(gymu\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39msas))\n\u001b[0;32m----> 8\u001b[0m s \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mconcatenate([x\u001b[38;5;241m.\u001b[39mstate, (x\u001b[38;5;241m.\u001b[39mnext_state \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mnext_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros_like(x\u001b[38;5;241m.\u001b[39mstate))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     11\u001b[0m J\u001b[38;5;241m.\u001b[39mimages([[x\u001b[38;5;241m.\u001b[39mstate] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset])\n",
      "File \u001b[0;32m~/Documents/repos/gymu/gymu/data/_torch/_tar.py:71\u001b[0m, in \u001b[0;36mComposable.mode.<locals>._mode_with_next_state\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mode_with_next_state\u001b[39m(source):\n\u001b[0;32m---> 71\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEXT_STATE \u001b[38;5;129;01min\u001b[39;00m x1: \u001b[38;5;66;03m# next state is already present in the data\u001b[39;00m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m mode(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mode\u001b[38;5;241m.\u001b[39mkeys()})\n",
      "File \u001b[0;32m~/Documents/repos/gymu/gymu/data/_torch/_tar.py:56\u001b[0m, in \u001b[0;36mComposable.decode.<locals>._decode\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode\u001b[39m(source):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m source:\n\u001b[1;32m     57\u001b[0m         x \u001b[38;5;241m=\u001b[39m {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m  np\u001b[38;5;241m.\u001b[39mload(io\u001b[38;5;241m.\u001b[39mBytesIO(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m'\u001b[39m]), allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/PhD/lib/python3.8/site-packages/webdataset/tariterators.py:150\u001b[0m, in \u001b[0;36mgroup_by_keys\u001b[0;34m(data, keys, lcase, suffixes, handler)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"Return function over iterator that groups key, value pairs into samples.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m:param keys: function that splits the key into key and extension (base_plus_ext)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m:param lcase: convert suffixes to lower case (Default value = True)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m current_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filesample \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filesample, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    152\u001b[0m     fname, value \u001b[38;5;241m=\u001b[39m filesample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m\"\u001b[39m], filesample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/PhD/lib/python3.8/site-packages/webdataset/tariterators.py:126\u001b[0m, in \u001b[0;36mtar_file_expander\u001b[0;34m(data, handler)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtar_file_expander\u001b[39m(data, handler\u001b[38;5;241m=\u001b[39mreraise_exception):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124;03m\"\"\"Expand a stream of open tar files into a stream of tar file contents.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    This returns an iterator over (filename, file_contents).\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    127\u001b[0m         info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/PhD/lib/python3.8/site-packages/webdataset/tariterators.py:80\u001b[0m, in \u001b[0;36murl_opener\u001b[0;34m(data, handler, **kw)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exn:\n\u001b[1;32m     79\u001b[0m     exn\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m exn\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m (url,)\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexn\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/PhD/lib/python3.8/site-packages/webdataset/handlers.py:24\u001b[0m, in \u001b[0;36mreraise_exception\u001b[0;34m(exn)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise_exception\u001b[39m(exn):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124;03m\"\"\"Call in an exception handler to re-raise the exception.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exn\n",
      "File \u001b[0;32m~/anaconda3/envs/PhD/lib/python3.8/site-packages/webdataset/tariterators.py:75\u001b[0m, in \u001b[0;36murl_opener\u001b[0;34m(data, handler, **kw)\u001b[0m\n\u001b[1;32m     73\u001b[0m url \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mgopen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     sample\u001b[38;5;241m.\u001b[39mupdate(stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m sample\n",
      "File \u001b[0;32m~/anaconda3/envs/PhD/lib/python3.8/site-packages/webdataset/gopen.py:250\u001b[0m, in \u001b[0;36mgopen\u001b[0;34m(url, mode, bufsize, **kw)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pr\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    249\u001b[0m     bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOPEN_BUFFER\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pr\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    252\u001b[0m     bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOPEN_BUFFER\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './NORMAL-300k/ep-0000.tar.gz'"
     ]
    }
   ],
   "source": [
    "import gymu\n",
    "import jnu as J\n",
    "import numpy as np\n",
    "\n",
    "dataset = gymu.data.dataset([\"./NORMAL-300k/ep-0000.tar.gz\",\"./NORMAL-300k/ep-0000.tar.gz\"]).then(gymu.data.Composable.decode())\n",
    "dataset = dataset.then(gymu.data.Composable.mode(gymu.mode.sas))\n",
    "\n",
    "s = [np.concatenate([x.state, (x.next_state if x.next_state is not None else np.zeros_like(x.state))], axis=-1) for x in dataset]\n",
    " \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1081993",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.images(s, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c182e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import gymu\n",
    "from gymu.data import Composable\n",
    "import gym_pygame\n",
    "import jnu as J\n",
    "\n",
    "\n",
    "env = gymu.make(\"Alone-v0\")\n",
    "iterator = gymu.iterator(env, mode=gymu.mode.sard, max_length=20)\n",
    "gymu.data.write_episode(iterator, path=\"Alone-v0/ep-0.tar.gz\")\n",
    "gymu.data.write_episode(iterator, path=\"Alone-v0/ep-1.tar.gz\")\n",
    "\n",
    "episodes = glob.glob(\"./Alone-v0/*.tar.gz\")\n",
    "dataset = gymu.data.dataset(episodes).then(Composable.decode())\n",
    "dataset = dataset.then(gymu.data.Composable.mode(gymu.mode.sas, ignore_last=False))\n",
    "\n",
    "s = [np.concatenate([x.state, (x.next_state if x.next_state is not None else np.zeros_like(x.state))], axis=-1) for x in dataset]\n",
    "J.images(s)      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fca24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jnu as J\n",
    "import itertools\n",
    "import gymu\n",
    "import glob\n",
    "from gymu.data import Composable\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "episodes = glob.glob(\"./NORMAL-300k/*.tar.gz\")\n",
    "\n",
    "dataset = gymu.data.dataset(episodes)\n",
    "dataset = dataset.then(Composable.mode(gymu.mode.sa))\n",
    "dataset = dataset.shuffle(256).batched(256)\n",
    "loader = DataLoader(dataset, batch_size=None, num_workers=12, prefetch_factor=16)\n",
    "\n",
    "for (s, a) in loader:\n",
    "    print(s.shape, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748134d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
